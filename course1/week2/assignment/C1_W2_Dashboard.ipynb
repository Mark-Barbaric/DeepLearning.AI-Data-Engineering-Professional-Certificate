{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Serving for Data Analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first part of the lab, you ingested data from a source database and transformed it using AWS Glue. In this notebook, you will serve the transformed data for an analytics example. You will perform data retrieval with Amazon Athena using simple SQL queries and then use the query output to build an interactive dashboard that explores sales data by country and product line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all of the required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import awswrangler as wr\n",
    "import seaborn as sns\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you have executed the AWS Glue job, a new database named `de-c1w2-analytics-db` was created and stored in the S3 instance. This database contains four tables with the following schema:\n",
    "\n",
    "![image alt ><](./images/schema_after_ETL.png)\n",
    "\n",
    "Each row in the `fact_orders` table corresponds to a sale order and contains related measurements such as quantity ordered and price. The dimension tables provide more context and details for each sale order such as customers' information, customers' locations, and order details. Your data is now ready to be served for analytics. To query this data from S3, you will use Amazon Athena. Let's check the data stored in the `dim_products` table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "QueryFailed",
     "evalue": "SCHEMA_NOT_FOUND: line 7:3: Schema 'de-c1w2-analytics-db' does not exist. You may need to manually clean the data at location 's3://aws-athena-query-results-058264381077-us-east-1/tables/2d9fc9fd-d771-4179-964f-867e274050c8' before retrying. Athena will not delete data in your account.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mQueryFailed\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m GLUE_DATABASE \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mde-c1w2-analytics-db\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m products_df \u001b[39m=\u001b[39m wr\u001b[39m.\u001b[39mathena\u001b[39m.\u001b[39mread_sql_query(\n\u001b[1;32m      4\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39m    SELECT * FROM dim_products\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m,\n\u001b[1;32m      7\u001b[0m     database\u001b[39m=\u001b[39mGLUE_DATABASE,\n\u001b[1;32m      8\u001b[0m )\n\u001b[1;32m     10\u001b[0m products_df\u001b[39m.\u001b[39mhead()\n",
      "File \u001b[0;32m~/miniconda/lib/python3.12/site-packages/awswrangler/_config.py:735\u001b[0m, in \u001b[0;36mapply_configs.<locals>.wrapper\u001b[0;34m(*args_raw, **kwargs)\u001b[0m\n\u001b[1;32m    733\u001b[0m         \u001b[39mdel\u001b[39;00m args[name]\n\u001b[1;32m    734\u001b[0m         args \u001b[39m=\u001b[39m {\u001b[39m*\u001b[39m\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkeywords}\n\u001b[0;32m--> 735\u001b[0m \u001b[39mreturn\u001b[39;00m function(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39margs)\n",
      "File \u001b[0;32m~/miniconda/lib/python3.12/site-packages/awswrangler/_utils.py:178\u001b[0m, in \u001b[0;36mvalidate_kwargs.<locals>.decorator.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[39mif\u001b[39;00m condition_fn() \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(passed_unsupported_kwargs) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    176\u001b[0m     \u001b[39mraise\u001b[39;00m exceptions\u001b[39m.\u001b[39mInvalidArgument(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mmessage\u001b[39m}\u001b[39;00m\u001b[39m `\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(passed_unsupported_kwargs)\u001b[39m}\u001b[39;00m\u001b[39m`.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 178\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda/lib/python3.12/site-packages/awswrangler/athena/_read.py:1080\u001b[0m, in \u001b[0;36mread_sql_query\u001b[0;34m(sql, database, ctas_approach, unload_approach, ctas_parameters, unload_parameters, categories, chunksize, s3_output, workgroup, encryption, kms_key, keep_files, use_threads, boto3_session, client_request_token, athena_cache_settings, data_source, athena_query_wait_polling_delay, params, paramstyle, dtype_backend, s3_additional_kwargs, pyarrow_additional_kwargs)\u001b[0m\n\u001b[1;32m   1077\u001b[0m ctas_bucketing_info \u001b[39m=\u001b[39m ctas_parameters\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mbucketing_info\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1078\u001b[0m ctas_write_compression \u001b[39m=\u001b[39m ctas_parameters\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mcompression\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 1080\u001b[0m \u001b[39mreturn\u001b[39;00m _resolve_query_without_cache(\n\u001b[1;32m   1081\u001b[0m     sql\u001b[39m=\u001b[39msql,\n\u001b[1;32m   1082\u001b[0m     database\u001b[39m=\u001b[39mdatabase,\n\u001b[1;32m   1083\u001b[0m     data_source\u001b[39m=\u001b[39mdata_source,\n\u001b[1;32m   1084\u001b[0m     ctas_approach\u001b[39m=\u001b[39mctas_approach,\n\u001b[1;32m   1085\u001b[0m     unload_approach\u001b[39m=\u001b[39munload_approach,\n\u001b[1;32m   1086\u001b[0m     unload_parameters\u001b[39m=\u001b[39munload_parameters,\n\u001b[1;32m   1087\u001b[0m     categories\u001b[39m=\u001b[39mcategories,\n\u001b[1;32m   1088\u001b[0m     chunksize\u001b[39m=\u001b[39mchunksize,\n\u001b[1;32m   1089\u001b[0m     s3_output\u001b[39m=\u001b[39ms3_output,\n\u001b[1;32m   1090\u001b[0m     workgroup\u001b[39m=\u001b[39mworkgroup,\n\u001b[1;32m   1091\u001b[0m     encryption\u001b[39m=\u001b[39mencryption,\n\u001b[1;32m   1092\u001b[0m     kms_key\u001b[39m=\u001b[39mkms_key,\n\u001b[1;32m   1093\u001b[0m     keep_files\u001b[39m=\u001b[39mkeep_files,\n\u001b[1;32m   1094\u001b[0m     ctas_database\u001b[39m=\u001b[39mctas_database,\n\u001b[1;32m   1095\u001b[0m     ctas_temp_table_name\u001b[39m=\u001b[39mctas_temp_table_name,\n\u001b[1;32m   1096\u001b[0m     ctas_bucketing_info\u001b[39m=\u001b[39mctas_bucketing_info,\n\u001b[1;32m   1097\u001b[0m     ctas_write_compression\u001b[39m=\u001b[39mctas_write_compression,\n\u001b[1;32m   1098\u001b[0m     athena_query_wait_polling_delay\u001b[39m=\u001b[39mathena_query_wait_polling_delay,\n\u001b[1;32m   1099\u001b[0m     use_threads\u001b[39m=\u001b[39muse_threads,\n\u001b[1;32m   1100\u001b[0m     s3_additional_kwargs\u001b[39m=\u001b[39ms3_additional_kwargs,\n\u001b[1;32m   1101\u001b[0m     boto3_session\u001b[39m=\u001b[39mboto3_session,\n\u001b[1;32m   1102\u001b[0m     pyarrow_additional_kwargs\u001b[39m=\u001b[39mpyarrow_additional_kwargs,\n\u001b[1;32m   1103\u001b[0m     execution_params\u001b[39m=\u001b[39mexecution_params,\n\u001b[1;32m   1104\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[1;32m   1105\u001b[0m     client_request_token\u001b[39m=\u001b[39mclient_request_token,\n\u001b[1;32m   1106\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda/lib/python3.12/site-packages/awswrangler/athena/_read.py:506\u001b[0m, in \u001b[0;36m_resolve_query_without_cache\u001b[0;34m(sql, database, data_source, ctas_approach, unload_approach, unload_parameters, categories, chunksize, s3_output, workgroup, encryption, kms_key, keep_files, ctas_database, ctas_temp_table_name, ctas_bucketing_info, ctas_write_compression, athena_query_wait_polling_delay, use_threads, s3_additional_kwargs, boto3_session, pyarrow_additional_kwargs, execution_params, dtype_backend, client_request_token)\u001b[0m\n\u001b[1;32m    504\u001b[0m     name \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtemp_table_\u001b[39m\u001b[39m{\u001b[39;00muuid\u001b[39m.\u001b[39muuid4()\u001b[39m.\u001b[39mhex\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    505\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 506\u001b[0m     \u001b[39mreturn\u001b[39;00m _resolve_query_without_cache_ctas(\n\u001b[1;32m    507\u001b[0m         sql\u001b[39m=\u001b[39msql,\n\u001b[1;32m    508\u001b[0m         database\u001b[39m=\u001b[39mdatabase,\n\u001b[1;32m    509\u001b[0m         data_source\u001b[39m=\u001b[39mdata_source,\n\u001b[1;32m    510\u001b[0m         s3_output\u001b[39m=\u001b[39ms3_output,\n\u001b[1;32m    511\u001b[0m         keep_files\u001b[39m=\u001b[39mkeep_files,\n\u001b[1;32m    512\u001b[0m         chunksize\u001b[39m=\u001b[39mchunksize,\n\u001b[1;32m    513\u001b[0m         categories\u001b[39m=\u001b[39mcategories,\n\u001b[1;32m    514\u001b[0m         encryption\u001b[39m=\u001b[39mencryption,\n\u001b[1;32m    515\u001b[0m         workgroup\u001b[39m=\u001b[39mworkgroup,\n\u001b[1;32m    516\u001b[0m         kms_key\u001b[39m=\u001b[39mkms_key,\n\u001b[1;32m    517\u001b[0m         alt_database\u001b[39m=\u001b[39mctas_database,\n\u001b[1;32m    518\u001b[0m         name\u001b[39m=\u001b[39mname,\n\u001b[1;32m    519\u001b[0m         ctas_bucketing_info\u001b[39m=\u001b[39mctas_bucketing_info,\n\u001b[1;32m    520\u001b[0m         ctas_write_compression\u001b[39m=\u001b[39mctas_write_compression,\n\u001b[1;32m    521\u001b[0m         athena_query_wait_polling_delay\u001b[39m=\u001b[39mathena_query_wait_polling_delay,\n\u001b[1;32m    522\u001b[0m         use_threads\u001b[39m=\u001b[39muse_threads,\n\u001b[1;32m    523\u001b[0m         s3_additional_kwargs\u001b[39m=\u001b[39ms3_additional_kwargs,\n\u001b[1;32m    524\u001b[0m         boto3_session\u001b[39m=\u001b[39mboto3_session,\n\u001b[1;32m    525\u001b[0m         pyarrow_additional_kwargs\u001b[39m=\u001b[39mpyarrow_additional_kwargs,\n\u001b[1;32m    526\u001b[0m         execution_params\u001b[39m=\u001b[39mexecution_params,\n\u001b[1;32m    527\u001b[0m         dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[1;32m    528\u001b[0m     )\n\u001b[1;32m    529\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    530\u001b[0m     catalog\u001b[39m.\u001b[39mdelete_table_if_exists(database\u001b[39m=\u001b[39mctas_database \u001b[39mor\u001b[39;00m database, table\u001b[39m=\u001b[39mname, boto3_session\u001b[39m=\u001b[39mboto3_session)\n",
      "File \u001b[0;32m~/miniconda/lib/python3.12/site-packages/awswrangler/athena/_read.py:324\u001b[0m, in \u001b[0;36m_resolve_query_without_cache_ctas\u001b[0;34m(sql, database, data_source, s3_output, keep_files, chunksize, categories, encryption, workgroup, kms_key, alt_database, name, ctas_bucketing_info, ctas_write_compression, athena_query_wait_polling_delay, use_threads, s3_additional_kwargs, boto3_session, pyarrow_additional_kwargs, execution_params, dtype_backend)\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_resolve_query_without_cache_ctas\u001b[39m(\n\u001b[1;32m    302\u001b[0m     sql: \u001b[39mstr\u001b[39m,\n\u001b[1;32m    303\u001b[0m     database: \u001b[39mstr\u001b[39m \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    322\u001b[0m     dtype_backend: Literal[\u001b[39m\"\u001b[39m\u001b[39mnumpy_nullable\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mpyarrow\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mnumpy_nullable\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    323\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m pd\u001b[39m.\u001b[39mDataFrame \u001b[39m|\u001b[39m Iterator[pd\u001b[39m.\u001b[39mDataFrame]:\n\u001b[0;32m--> 324\u001b[0m     ctas_query_info: \u001b[39mdict\u001b[39m[\u001b[39mstr\u001b[39m, \u001b[39mstr\u001b[39m \u001b[39m|\u001b[39m _QueryMetadata] \u001b[39m=\u001b[39m create_ctas_table(\n\u001b[1;32m    325\u001b[0m         sql\u001b[39m=\u001b[39msql,\n\u001b[1;32m    326\u001b[0m         database\u001b[39m=\u001b[39mdatabase,\n\u001b[1;32m    327\u001b[0m         ctas_table\u001b[39m=\u001b[39mname,\n\u001b[1;32m    328\u001b[0m         ctas_database\u001b[39m=\u001b[39malt_database,\n\u001b[1;32m    329\u001b[0m         bucketing_info\u001b[39m=\u001b[39mctas_bucketing_info,\n\u001b[1;32m    330\u001b[0m         data_source\u001b[39m=\u001b[39mdata_source,\n\u001b[1;32m    331\u001b[0m         s3_output\u001b[39m=\u001b[39ms3_output,\n\u001b[1;32m    332\u001b[0m         workgroup\u001b[39m=\u001b[39mworkgroup,\n\u001b[1;32m    333\u001b[0m         encryption\u001b[39m=\u001b[39mencryption,\n\u001b[1;32m    334\u001b[0m         write_compression\u001b[39m=\u001b[39mctas_write_compression,\n\u001b[1;32m    335\u001b[0m         kms_key\u001b[39m=\u001b[39mkms_key,\n\u001b[1;32m    336\u001b[0m         wait\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    337\u001b[0m         athena_query_wait_polling_delay\u001b[39m=\u001b[39mathena_query_wait_polling_delay,\n\u001b[1;32m    338\u001b[0m         boto3_session\u001b[39m=\u001b[39mboto3_session,\n\u001b[1;32m    339\u001b[0m         execution_params\u001b[39m=\u001b[39mexecution_params,\n\u001b[1;32m    340\u001b[0m     )\n\u001b[1;32m    341\u001b[0m     fully_qualified_name: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mctas_query_info[\u001b[39m\"\u001b[39m\u001b[39mctas_database\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mctas_query_info[\u001b[39m\"\u001b[39m\u001b[39mctas_table\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    342\u001b[0m     ctas_query_metadata \u001b[39m=\u001b[39m cast(_QueryMetadata, ctas_query_info[\u001b[39m\"\u001b[39m\u001b[39mctas_query_metadata\u001b[39m\u001b[39m\"\u001b[39m])\n",
      "File \u001b[0;32m~/miniconda/lib/python3.12/site-packages/awswrangler/_config.py:735\u001b[0m, in \u001b[0;36mapply_configs.<locals>.wrapper\u001b[0;34m(*args_raw, **kwargs)\u001b[0m\n\u001b[1;32m    733\u001b[0m         \u001b[39mdel\u001b[39;00m args[name]\n\u001b[1;32m    734\u001b[0m         args \u001b[39m=\u001b[39m {\u001b[39m*\u001b[39m\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkeywords}\n\u001b[0;32m--> 735\u001b[0m \u001b[39mreturn\u001b[39;00m function(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39margs)\n",
      "File \u001b[0;32m~/miniconda/lib/python3.12/site-packages/awswrangler/athena/_utils.py:844\u001b[0m, in \u001b[0;36mcreate_ctas_table\u001b[0;34m(sql, database, ctas_table, ctas_database, s3_output, storage_format, write_compression, partitioning_info, bucketing_info, field_delimiter, schema_only, workgroup, data_source, encryption, kms_key, categories, wait, athena_query_wait_polling_delay, execution_params, boto3_session)\u001b[0m\n\u001b[1;32m    839\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mColumn type is unknown\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m msg:\n\u001b[1;32m    840\u001b[0m             \u001b[39mraise\u001b[39;00m exceptions\u001b[39m.\u001b[39mInvalidArgumentValue(\n\u001b[1;32m    841\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mPlease, don\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt leave undefined columns types in your query. You can cast to ensure it. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    842\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m(E.g. \u001b[39m\u001b[39m'\u001b[39m\u001b[39mSELECT CAST(NULL AS INTEGER) AS MY_COL, ...\u001b[39m\u001b[39m'\u001b[39m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    843\u001b[0m             )\n\u001b[0;32m--> 844\u001b[0m         \u001b[39mraise\u001b[39;00m ex\n\u001b[1;32m    845\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    846\u001b[0m     response[\u001b[39m\"\u001b[39m\u001b[39mctas_query_id\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m query_execution_id\n",
      "File \u001b[0;32m~/miniconda/lib/python3.12/site-packages/awswrangler/athena/_utils.py:822\u001b[0m, in \u001b[0;36mcreate_ctas_table\u001b[0;34m(sql, database, ctas_table, ctas_database, s3_output, storage_format, write_compression, partitioning_info, bucketing_info, field_delimiter, schema_only, workgroup, data_source, encryption, kms_key, categories, wait, athena_query_wait_polling_delay, execution_params, boto3_session)\u001b[0m\n\u001b[1;32m    820\u001b[0m \u001b[39mif\u001b[39;00m wait:\n\u001b[1;32m    821\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 822\u001b[0m         response[\u001b[39m\"\u001b[39m\u001b[39mctas_query_metadata\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m _get_query_metadata(\n\u001b[1;32m    823\u001b[0m             query_execution_id\u001b[39m=\u001b[39mquery_execution_id,\n\u001b[1;32m    824\u001b[0m             boto3_session\u001b[39m=\u001b[39mboto3_session,\n\u001b[1;32m    825\u001b[0m             categories\u001b[39m=\u001b[39mcategories,\n\u001b[1;32m    826\u001b[0m             metadata_cache_manager\u001b[39m=\u001b[39m_cache_manager,\n\u001b[1;32m    827\u001b[0m             athena_query_wait_polling_delay\u001b[39m=\u001b[39mathena_query_wait_polling_delay,\n\u001b[1;32m    828\u001b[0m         )\n\u001b[1;32m    829\u001b[0m     \u001b[39mexcept\u001b[39;00m exceptions\u001b[39m.\u001b[39mQueryFailed \u001b[39mas\u001b[39;00m ex:\n\u001b[1;32m    830\u001b[0m         msg: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(ex)\n",
      "File \u001b[0;32m~/miniconda/lib/python3.12/site-packages/awswrangler/athena/_utils.py:231\u001b[0m, in \u001b[0;36m_get_query_metadata\u001b[0;34m(query_execution_id, boto3_session, categories, query_execution_payload, metadata_cache_manager, athena_query_wait_polling_delay, execution_params, dtype_backend)\u001b[0m\n\u001b[1;32m    229\u001b[0m     _query_execution_payload: \u001b[39mdict\u001b[39m[\u001b[39mstr\u001b[39m, Any] \u001b[39m=\u001b[39m query_execution_payload\n\u001b[1;32m    230\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 231\u001b[0m     _query_execution_payload \u001b[39m=\u001b[39m _executions\u001b[39m.\u001b[39mwait_query(\n\u001b[1;32m    232\u001b[0m         query_execution_id\u001b[39m=\u001b[39mquery_execution_id,\n\u001b[1;32m    233\u001b[0m         boto3_session\u001b[39m=\u001b[39mboto3_session,\n\u001b[1;32m    234\u001b[0m         athena_query_wait_polling_delay\u001b[39m=\u001b[39mathena_query_wait_polling_delay,\n\u001b[1;32m    235\u001b[0m     )\n\u001b[1;32m    236\u001b[0m cols_types: \u001b[39mdict\u001b[39m[\u001b[39mstr\u001b[39m, \u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m get_query_columns_types(\n\u001b[1;32m    237\u001b[0m     query_execution_id\u001b[39m=\u001b[39mquery_execution_id, boto3_session\u001b[39m=\u001b[39mboto3_session\n\u001b[1;32m    238\u001b[0m )\n\u001b[1;32m    239\u001b[0m _logger\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mCasting query column types: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, cols_types)\n",
      "File \u001b[0;32m~/miniconda/lib/python3.12/site-packages/awswrangler/_config.py:735\u001b[0m, in \u001b[0;36mapply_configs.<locals>.wrapper\u001b[0;34m(*args_raw, **kwargs)\u001b[0m\n\u001b[1;32m    733\u001b[0m         \u001b[39mdel\u001b[39;00m args[name]\n\u001b[1;32m    734\u001b[0m         args \u001b[39m=\u001b[39m {\u001b[39m*\u001b[39m\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkeywords}\n\u001b[0;32m--> 735\u001b[0m \u001b[39mreturn\u001b[39;00m function(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39margs)\n",
      "File \u001b[0;32m~/miniconda/lib/python3.12/site-packages/awswrangler/athena/_executions.py:236\u001b[0m, in \u001b[0;36mwait_query\u001b[0;34m(query_execution_id, boto3_session, athena_query_wait_polling_delay)\u001b[0m\n\u001b[1;32m    234\u001b[0m _logger\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mQuery state change reason: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, response[\u001b[39m\"\u001b[39m\u001b[39mStatus\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mStateChangeReason\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m    235\u001b[0m \u001b[39mif\u001b[39;00m state \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mFAILED\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 236\u001b[0m     \u001b[39mraise\u001b[39;00m exceptions\u001b[39m.\u001b[39mQueryFailed(response[\u001b[39m\"\u001b[39m\u001b[39mStatus\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mStateChangeReason\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m    237\u001b[0m \u001b[39mif\u001b[39;00m state \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mCANCELLED\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    238\u001b[0m     \u001b[39mraise\u001b[39;00m exceptions\u001b[39m.\u001b[39mQueryCancelled(response[\u001b[39m\"\u001b[39m\u001b[39mStatus\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mStateChangeReason\u001b[39m\u001b[39m\"\u001b[39m))\n",
      "\u001b[0;31mQueryFailed\u001b[0m: SCHEMA_NOT_FOUND: line 7:3: Schema 'de-c1w2-analytics-db' does not exist. You may need to manually clean the data at location 's3://aws-athena-query-results-058264381077-us-east-1/tables/2d9fc9fd-d771-4179-964f-867e274050c8' before retrying. Athena will not delete data in your account."
     ]
    }
   ],
   "source": [
    "GLUE_DATABASE = \"de-c1w2-analytics-db\"\n",
    "\n",
    "products_df = wr.athena.read_sql_query(\n",
    "    \"\"\"\n",
    "    SELECT * FROM dim_products\n",
    "    \"\"\",\n",
    "    database=GLUE_DATABASE,\n",
    ")\n",
    "    \n",
    "products_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can get some data insights by aggregating some sale measurements from the fact table. In the following cell, you will compute the total sales amount spent by each country and display the top 10 records:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve total sales per country by joining the 'fact_orders' table with 'dim_locations' on postal code.\n",
    "# The result is grouped by the 'country' column, and the total sales for each country is calculated as the sum of order amounts.\n",
    "# The query is executed using Athena through the 'wr.athena.read_sql_query' method, and the top 10 countries with the highest total sales are displayed.\n",
    "product_sales_by_country_df = wr.athena.read_sql_query(\n",
    "    \"\"\"\n",
    "    SELECT\n",
    "        dim_locations.country,\n",
    "        SUM(fact_orders.orderAmount) AS total_sales\n",
    "    FROM\n",
    "        fact_orders\n",
    "    JOIN\n",
    "        dim_locations ON fact_orders.postalCode = dim_locations.postalCode\n",
    "    GROUP BY 1\n",
    "    \"\"\",\n",
    "    database=GLUE_DATABASE,\n",
    ")\n",
    "    \n",
    "product_sales_by_country_df.sort_values(\"total_sales\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you will combine data from three tables: `fact_orders`, `dim_products`, and `dim_locations`. The query will select the order date, product line, product name, country, and total sales amount, grouping the results by order date, product line, product name, and country:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve detailed sales information by joining 'fact_orders' with 'dim_products' and 'dim_locations'.\n",
    "# The query selects order date, product line, product name, country, and calculates the total sales (sum of order amounts).\n",
    "# The result is grouped by order date, product line, product name, and country.\n",
    "# The query is executed using Athena through the 'wr.athena.read_sql_query' method, and the resulting DataFrame is displayed with the first few rows using 'head()'.\n",
    "product_sales_df = wr.athena.read_sql_query(\n",
    "    \"\"\"\n",
    "    SELECT\n",
    "        fact_orders.orderDate,\n",
    "        dim_products.productLine,\n",
    "        dim_products.productName,\n",
    "        dim_locations.country,\n",
    "        SUM(fact_orders.orderAmount) AS total_sales\n",
    "    FROM\n",
    "        fact_orders\n",
    "    JOIN\n",
    "        dim_products ON fact_orders.productCode = dim_products.productCode\n",
    "    JOIN\n",
    "        dim_locations ON fact_orders.postalCode = dim_locations.postalCode\n",
    "    GROUP BY 1, 2, 3, 4\n",
    "    \"\"\",\n",
    "    database=GLUE_DATABASE,\n",
    ")\n",
    "    \n",
    "product_sales_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will now use the query results to build an interactive dashboard using dropdown widgets, where you will be able to select a country and product line, filter the results based on a particular period of sales, showing the top N popular products at the end:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_sales_df['orderdate'] = pd.to_datetime(product_sales_df['orderdate'])\n",
    "\n",
    "# Ignore warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Country Dropdown Widget\n",
    "country_widget = widgets.Dropdown(\n",
    "    options=[\"ALL\"] + sorted(list(product_sales_df.country.unique())),\n",
    "    value=\"ALL\",\n",
    "    description=\"Country\",\n",
    ")\n",
    "\n",
    "# Product Line Dropdown Widget\n",
    "productline_widget = widgets.Dropdown(\n",
    "    options=[\"ALL\"] + sorted(list(product_sales_df.productline.unique())),\n",
    "    value=\"ALL\",\n",
    "    description=\"Product Line\",\n",
    ")\n",
    "\n",
    "# Interactive Widgets for Date Range, Country, Product Line, and Top N\n",
    "@widgets.interact(\n",
    "    start_date=widgets.DatePicker(value=product_sales_df.orderdate.min(), description=\"Start Date\"),\n",
    "    end_date=widgets.DatePicker(value=product_sales_df.orderdate.max(), description=\"End Date\"),\n",
    "    country=country_widget,\n",
    "    productline=productline_widget,\n",
    "    top_n=widgets.IntSlider(value=5, min=1, max=10, step=1, description=\"Top N\"),\n",
    ")\n",
    "\n",
    "# Function to Plot Top N Sales\n",
    "def plot_top_n_sales(start_date, end_date, country, productline, top_n):\n",
    "    \n",
    "    # Filter data based on selected date range\n",
    "    filtered_df = product_sales_df[\n",
    "        (product_sales_df.orderdate >= pd.Timestamp(start_date))\n",
    "        & (product_sales_df.orderdate <= pd.Timestamp(end_date))\n",
    "    ]\n",
    "    filtered_df = filtered_df.drop('orderdate', axis=1)\n",
    "    filtered_df = filtered_df.groupby(['productline', 'productname', 'country']).sum().reset_index()\n",
    "\n",
    "    # Build title string based on selected filters\n",
    "    title_str = f\"Top {top_n} Popular \"\n",
    "    \n",
    "    if productline != \"ALL\":\n",
    "        filtered_df = filtered_df[filtered_df.productline == productline]\n",
    "        title_str += productline\n",
    "    else: \n",
    "        filtered_df = filtered_df.groupby(['productname', 'country']).sum().reset_index()\n",
    "        title_str += \"Products\"\n",
    "        \n",
    "    if country != \"ALL\":\n",
    "        filtered_df = filtered_df[filtered_df.country == country]\n",
    "        title_str += \" in \" + country\n",
    "    else:\n",
    "        filtered_df = filtered_df.groupby(['productname']).sum().reset_index()\n",
    "\n",
    "    # Plotting the bar chart\n",
    "    if not (filtered_df.empty):\n",
    "        try:\n",
    "            ax = sns.barplot(\n",
    "                x=\"total_sales\",\n",
    "                y=\"productname\",\n",
    "                data=filtered_df.sort_values(\"total_sales\", ascending=False).head(top_n)\n",
    "            )\n",
    "        \n",
    "\n",
    "            ax.set(\n",
    "                xlabel=\"Total Sales\",\n",
    "                ylabel=\"Product Name\",\n",
    "                title=title_str\n",
    "            )\n",
    "        except:\n",
    "            print(\"error\")\n",
    "    else:\n",
    "        print(f\"There were no sales of {productline} to {country} during that period\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fantastic! You can now observe how effortlessly the data can be accessed after having transformed it into a form that is more appropriate for analytics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (base)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
